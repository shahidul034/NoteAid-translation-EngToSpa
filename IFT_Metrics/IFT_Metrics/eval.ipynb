{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this folder, we will try to have a single or maybe like a script to compute all the required metrics given the input along with its target column name for IFT and Also for EFT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IFT Metrics\n",
    "1. ROUGE-1-R\n",
    "2. ROUGE-L-R\n",
    "3. ROUGE-L-F\n",
    "4. BLEURT\n",
    "5. BERTScore-F\n",
    "6. BERTScore-R - \n",
    "7. UMLS-F\n",
    "8. LLM-as-a-Judge rating - with GPT-4o-mini\n",
    "9. Winrate (with GPT-4o it might be reliable)\n",
    "\n",
    "all in one environment: eval_metrics, added following\n",
    "- bert_score==0.3.13\n",
    "- bleurt==0.0.2\n",
    "- tensorflow==2.16.1\n",
    "- rouge-score==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# load bert-score module\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbert_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTScorer\n\u001b[0;32m----> 9\u001b[0m bert_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mBERTScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrescale_with_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/deberta-xlarge-mnli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# # load bleurt-score module\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# from bleurt import score\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# checkpoint = \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Evaluation_Metrics/ClinicalBLEURT/BLEURT-20\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# # checkpoint = \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Evaluation_Metrics/ClinicalBLEURT/ClinicalBLEURT\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# bleurt_scorer = score.BleurtScorer(checkpoint)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(\"Loaded BLEURT-20 checkpoint!!!!\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/bert_score/scorer.py:97\u001b[0m, in \u001b[0;36mBERTScorer.__init__\u001b[0;34m(self, model_type, num_layers, batch_size, nthreads, all_layers, idf, idf_sents, device, lang, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Building model and tokenizer\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_fast_tokenizer \u001b[38;5;241m=\u001b[39m use_fast_tokenizer\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_fast_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m get_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_layers)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/bert_score/utils.py:329\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(model_type, use_fast)\u001b[0m\n\u001b[1;32m    326\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m cache_scibert(model_type)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(trans_version) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 329\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_fast, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast tokenizer is not available for version < 4.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:857\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    859\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:689\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    688\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 689\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:923\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1291\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/huggingface_hub/utils/_http.py:93\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/connection.py:693\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/lianfu/lib/python3.8/socket.py:930\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# load rouge score module\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# load bert-score module\n",
    "from bert_score import BERTScorer\n",
    "bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True, model_type=\"microsoft/deberta-xlarge-mnli\")\n",
    "\n",
    "# # load bleurt-score module\n",
    "# from bleurt import score\n",
    "# checkpoint = \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Evaluation_Metrics/ClinicalBLEURT/BLEURT-20\"\n",
    "# # checkpoint = \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Evaluation_Metrics/ClinicalBLEURT/ClinicalBLEURT\"\n",
    "# bleurt_scorer = score.BleurtScorer(checkpoint)\n",
    "# print(\"Loaded BLEURT-20 checkpoint!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umls import AutomaticFactEval\n",
    "# umls_scorer = AutomaticFactEval()\n",
    "\n",
    "from gpt4o_mini_as_a_judge import llm_as_a_judge_prompt, get_openai_response, get_final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFTEvalMetrics:\n",
    "    def __init__(self, datapath, target_name, prediction_name):\n",
    "        self.data = pd.read_csv(datapath)\n",
    "        self.target_name = target_name\n",
    "        self.prediction_name = prediction_name\n",
    "        self.target = self.data[target_name].fillna(\"\").tolist()\n",
    "        self.generated = self.data[prediction_name].fillna(\"\").tolist()\n",
    "        self.res = {}\n",
    "\n",
    "    def _rouge(self):\n",
    "\n",
    "        r1 = {'p': [], 'r' : [], 'f': []}\n",
    "        r2 = {'p': [], 'r' : [], 'f': []}\n",
    "        rl = {'p': [], 'r' : [], 'f': []}\n",
    "        \n",
    "        rouge_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "        for i in range(len(self.data)):\n",
    "            all_rouge_scores = rouge_instance.score(self.target[i], self.generated[i])\n",
    "            r1['p'].append(all_rouge_scores['rouge1'][0])\n",
    "            r1['r'].append(all_rouge_scores['rouge1'][1])\n",
    "            r1['f'].append(all_rouge_scores['rouge1'][2])\n",
    "\n",
    "            r2['p'].append(all_rouge_scores['rouge2'][0])\n",
    "            r2['r'].append(all_rouge_scores['rouge2'][1])\n",
    "            r2['f'].append(all_rouge_scores['rouge2'][2])\n",
    "\n",
    "            rl['p'].append(all_rouge_scores['rougeL'][0])\n",
    "            rl['r'].append(all_rouge_scores['rougeL'][1])\n",
    "            rl['f'].append(all_rouge_scores['rougeL'][2])\n",
    "\n",
    "        self.res['rouge-1'] = (sum(r1['p'])/len(r1['p']), sum(r1['r'])/len(r1['r']), sum(r1['f'])/len(r1['f']))\n",
    "        self.res['rouge-2'] = (sum(r2['p'])/len(r2['p']), sum(r2['r'])/len(r2['r']), sum(r2['f'])/len(r2['f']))\n",
    "        self.res['rouge-l'] = (sum(rl['p'])/len(rl['p']), sum(rl['r'])/len(rl['r']), sum(rl['f'])/len(rl['f']))\n",
    "    \n",
    "    def _bleurt(self):\n",
    "        bleurt_scores = bleurt_scorer.score(references=self.target, candidates=self.generated)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.res['bleurt'] = sum(bleurt_scores)/len(bleurt_scores)\n",
    "\n",
    "    def _bertscore(self):\n",
    "        bert_P, bert_R, bert_F = bert_scorer.score(self.target, self.generated)\n",
    "        self.res['bertscore_p'] = bert_P.mean().item()\n",
    "        self.res['bertscore_r'] = bert_R.mean().item()\n",
    "        self.res['bertscore_f'] = bert_F.mean().item()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    \n",
    "    def _umls(self):\n",
    "        umls_scores = umls_scorer.run_source_concept_faithfulness(ref_sums=self.target, gen_sums=self.generated)\n",
    "        self.res['umls_f'] = umls_scores['UMLS_cuis_f']\n",
    "\n",
    "    def _llm_as_a_judge(self, judge_model='gpt-4o-mini'):\n",
    "        if 'dialogue' not in self.data.columns:\n",
    "            print(\"LLM as a judge is not applicable\")\n",
    "            return \n",
    "        print(self.data.iloc[0][\"dialogue\"])\n",
    "        print(self.data.columns)\n",
    "        self.data['judge_prompt'] = self.data.apply(lambda x: llm_as_a_judge_prompt(x['dialogue'], x[self.prediction_name]), 1)\n",
    "\n",
    "        all_responses = []\n",
    "        all_scores = []\n",
    "        for i in range(len(self.data)):\n",
    "            \n",
    "            judge_prompt = self.data.iloc[i]['judge_prompt']\n",
    "\n",
    "            try:\n",
    "                response = get_openai_response(prompt=judge_prompt, model=judge_model)\n",
    "            except:\n",
    "                print(\"########## Issue with OpenAI API\")\n",
    "                response = \"\"\n",
    "\n",
    "            all_responses.append(response)\n",
    "            \n",
    "            score = get_final_score(response)\n",
    "            all_scores.append(score)\n",
    "\n",
    "        self.data['gpt_4o_mini_responses'] = all_responses\n",
    "        self.data['gpt_4o_mini_scores'] = all_scores\n",
    "\n",
    "        self.res['llm_as_a_judge'] = self.data['gpt_4o_mini_scores'].describe()['mean']\n",
    "\n",
    "    def _winrate(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def run(self, judge_model='gpt-4o-mini'):\n",
    "        # self._rouge()\n",
    "        # print(\"Rouge Computed\")\n",
    "        # print(self.res)\n",
    "\n",
    "        # self._bleurt()\n",
    "        # print(\"BLEURT Computed\")\n",
    "        # print(self.res)\n",
    "\n",
    "        # self._bertscore()\n",
    "        # print(\"BERTScore Computed\")\n",
    "        # print(self.res)\n",
    "\n",
    "        # self._umls()\n",
    "        # print(\"UMLS Computed\")\n",
    "        # print(self.res)\n",
    "\n",
    "        print(\"LLM-as-a-Judge computing.....\")\n",
    "        self._llm_as_a_judge(judge_model=judge_model)\n",
    "        print(\"LLM-as-a-Judge Computed\")\n",
    "        # print(self.res)\n",
    "        \n",
    "        return self.res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_results(results_dict):\n",
    "    # print(\"Rouge-1-R: \", results_dict['rouge-1'][1])\n",
    "    # print(\"Rouge-L-R: \", results_dict['rouge-l'][1])\n",
    "    # print(\"Rouge-L-F: \", results_dict['rouge-l'][2])\n",
    "    # print(\"BLEURT: \", results_dict['bleurt'])\n",
    "    # print(\"BERTScore-F: \", results_dict['bertscore_f'])\n",
    "    # print(\"UMLS-F: \", results_dict['umls_f'])\n",
    "    \n",
    "    \n",
    "    print(\"LLM-as-a-Judge: \", results_dict['llm_as_a_judge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ift_models = [(\"gpt4\", \"gpt4_predictions\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/self_rewarding/GPT4_Test_Predictions/GPT4_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023_correct_prompt.csv\"),\n",
    "    ('opus', \"claude_opus_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Opus_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             ('sonet', \"claude_sonet_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Sonet_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"gpt-4o-mini\", \"gpt_4o_mini_predictions\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT-4o-mini/GPT-4o-mini_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             ('gpt3', \"gpt3_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT3/GPT3_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"haiku\", \"claude_haiku_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Haiku_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"R1-M0\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m0_mistral/ift_performance/m0_mistral.csv\"),\n",
    "             (\"R1-M1\", \"biomistral_responses\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m1_mistral/ift_performance/M1_low_eft_data-0.4_ep-2_rank-32.csv\"),\n",
    "             (\"R1-M2\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m2_mistral/ift_performance/M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2.csv\"),\n",
    "             (\"R1-M3\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m3_mistral/ift_performance/M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M4\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m4_mistral/ift_performance/M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M5\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m5_mistral/ift_performance/M5_model_M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-64.csv\")\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-as-a-Judge computing.....\n",
      "Doctor: Hello, how are you today?\n",
      "Patient: Not good. \n",
      "Doctor: What happened? \n",
      "Patient: I have a lot of congestion. I also am coughing a lot. It feels like I am choking on something.\n",
      "Index(['ID', 'section_header', 'section_text', 'dialogue',\n",
      "       'gpt4_few_shot_prompt', 'max_tokens', 'claude_haiku_predictions'],\n",
      "      dtype='object')\n",
      "LLM-as-a-Judge Computed\n",
      "LLM-as-a-Judge:  -1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "idx=5 #3,5 - computing 4o-mini and haiku models BERTScore performances\n",
    "eval_metric = IFTEvalMetrics(datapath=all_ift_models[idx][2],\n",
    "                              target_name='section_text', \n",
    "                              prediction_name=all_ift_models[idx][1])\n",
    "\n",
    "results = eval_metric.run(judge_model='gpt-4o-mini')\n",
    "get_final_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idx=3\n",
    "# eval_metric = IFTEvalMetrics(datapath=all_ift_models[idx][2],\n",
    "#                               target_name='section_text', \n",
    "#                               prediction_name=all_ift_models[idx][1])\n",
    "\n",
    "curr_model = '/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/mix_models/experiments/m2_mistral_tuning/ift_performance/M2_model_base-M1_low_eft_data-0.4_ep-2_rank-32_gen-M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_beta-0.1.csv'\n",
    "eval_metric = IFTEvalMetrics(datapath=curr_model,\n",
    "                              target_name='section_text', \n",
    "                              prediction_name=\"biomistral_responses\")\n",
    "results = eval_metric.run(judge_model='gpt-4o-mini')\n",
    "get_final_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4o-mini - 'bertscore_r': 0.3961123526096344, 'bertscore_f': 0.3974961042404175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath=\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/self_rewarding/GPT4_Test_Predictions/GPT4_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023_correct_prompt.csv\"\n",
    "# target_name='section_text'\n",
    "# prediction_name='gpt4_predictions'\n",
    "# print(f\"sbatch eval.sh {datapath} {target_name} {prediction_name} no_judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_results(results_dict):\n",
    "    try:\n",
    "        print(\"Rouge-1-R: \", results_dict['rouge-1'][1])\n",
    "        print(\"Rouge-L-R: \", results_dict['rouge-l'][1])\n",
    "        print(\"Rouge-L-F: \", results_dict['rouge-l'][2])\n",
    "        print(\"BLEURT: \", results_dict['bleurt'])\n",
    "        print(\"BERTScore-F: \", results_dict['bertscore_f'])\n",
    "        print(\"UMLS-F: \", results_dict['umls_f'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"LLM-as-a-Judge: \", results_dict['llm_as_a_judge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_final_results(gpt4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All IFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ift_models = [(\"gpt4\", \"gpt4_predictions\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/self_rewarding/GPT4_Test_Predictions/GPT4_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023_correct_prompt.csv\"),\n",
    "    ('opus', \"claude_opus_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Opus_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             ('sonet', \"claude_sonet_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Sonet_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"gpt-4o-mini\", \"gpt_4o_mini_predictions\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT-4o-mini/GPT-4o-mini_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             ('gpt3', \"gpt3_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT3/GPT3_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"haiku\", \"claude_haiku_predictions\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/Claude_Haiku_MTS-Dialog-TestSet-2-MEDIQA-Sum-2023.csv\"),\n",
    "             (\"R1-M0\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m0_mistral/ift_performance/m0_mistral.csv\"),\n",
    "             (\"R1-M1\", \"biomistral_responses\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m1_mistral/ift_performance/M1_low_eft_data-0.4_ep-2_rank-32.csv\"),\n",
    "             (\"R1-M2\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m2_mistral/ift_performance/M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2.csv\"),\n",
    "             (\"R1-M3\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m3_mistral/ift_performance/M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M4\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m4_mistral/ift_performance/M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M5\", 'biomistral_responses', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m5_mistral/ift_performance/M5_model_M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-64.csv\")\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eval_metric = IFTEvalMetrics(datapath=all_ift_models[5][2],\n",
    "                              target_name='section_text', \n",
    "                              prediction_name=all_ift_models[5][1])\n",
    "\n",
    "gpt4_results = eval_metric.run(judge_model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_final_results(gpt4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFT Metrics\n",
    "1. Pearson\n",
    "2. Spearman Rank\n",
    "3. Kendall's Tau\n",
    "4. Micro F1\n",
    "5. Macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eft_models = [('opus', \"claude_opus_scores\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/val_data_rank_responses_with_gpt4_scores_and_claude_opus_scores.csv\"),\n",
    "             ('sonet', \"claude_sonet_scores\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/val_data_rank_responses_with_gpt4_scores_and_claude_sonet_scores.csv\"),\n",
    "             (\"gpt-4o-mini\", \"gpt_4o_mini_scores\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT-4o-mini/val_data_rank_responses_with_gpt4_scores_and_gpt_4o_mini_scores.csv\"),\n",
    "             ('gpt3', \"gpt3_scores\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT3/val_data_rank_responses_with_gpt4_scores_and_gpt3_scores.csv\"),\n",
    "             (\"haiku\", \"claude_haiku_scores\",\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/Claude/val_data_rank_responses_with_gpt4_scores_and_claude_haiku_scores.csv\"),\n",
    "             (\"R1-M0\", 'biomistral_scores', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m0_mistral/eft_performance/m0_mistral.csv\"),\n",
    "             (\"R1-M1\", \"biomistral_scores\", \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m1_mistral/eft_performance/M1_low_eft_data-0.4_ep-2_rank-32.csv\"),\n",
    "             (\"R1-M2\", 'biomistral_scores', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m2_mistral/eft_performance/M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2.csv\"),\n",
    "             (\"R1-M3\", 'biomistral_scores', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m3_mistral/eft_performance/M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M4\", 'biomistral_scores', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m4_mistral/eft_performance/M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16.csv\"),\n",
    "             (\"R1-M5\", 'biomistral_scores', \"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/summer_2024/low_eft_data/experiments/m5_mistral/eft_performance/M5_model_M4_model_M3_model_M2_model_M1_low_eft_data-0.4_ep-2_rank-32_temp-1.0_lr-5e-05_ep-2_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-16_temp-1.0_lr-5e-05_ep-_rank-64.csv\")\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"python eft_eval.py {all_eft_models[2][2]} {all_eft_models[2][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_eft_data = pd.read_csv(\"/project/pi_hongyu_umass_edu/zonghai/clinical-llm-alignment/durga_sandeep/Self-Rewarding-LM/analysis/GPT3_vs_Sonet/eft_test_data_balanced_with_gpt3_scores.csv\")\n",
    "# # balanced_eft_data[['ID', 'section_header', 'dialogue', 'section_text', \"llm_as_a_judge_prompt\", \"gpt4_scores\"]].to_csv(\"balanced_eft_test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
