{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def direct_translate(sentence):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate the following text from English into Spanish: {sentence}\"}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mshahidul/project1/all_tran_data/Sampled_100_MedlinePlus_eng_spanish_pair.json', 'r') as file:\n",
    "    lines = file.read().split('\\n')\n",
    "translated_lines = []\n",
    "import tqdm\n",
    "for line in tqdm.tqdm(lines[:1000]):\n",
    "    translated_line = direct_translate(line)\n",
    "    translated_lines.append({\n",
    "        \"original\": line,\n",
    "        \"translated_spanish\": translated_line\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the output file path\n",
    "output_file = \"/home/mshahidul/project1/code/translated_MedlinePlus.json\"\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(translated_lines, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Translation saved successfully to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_bleu_chrf\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "file_path = \"/home/mshahidul/project1/all_tran_data/Sampled_100_MedlinePlus_eng_spanish_pair.json\"\n",
    "from utils import compute_bleu_chrf\n",
    "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "    original_file = json.load(json_file)\n",
    "total_score=[]\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "cache_directory = \"/data/data_user_alpha/public_models\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_directory, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_directory)\n",
    "model.to(\"cuda\")\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for line in tqdm.tqdm(original_file):\n",
    "    hypothesis_text = translator(line['english'], src_lang=\"eng_Latn\", tgt_lang=\"spa_Latn\", max_length=400)[0]['translation_text']\n",
    "    # hypothesis_text = direct_translate(line['english'])\n",
    "    reference_text = line['spanish']\n",
    "    score=compute_bleu_chrf(reference_text, hypothesis_text)  \n",
    "    total_score.append({\n",
    "        \"original_english\": line['english'],\n",
    "        \"original_spanish\": line['spanish'],\n",
    "        \"translated_spanish\": hypothesis_text,\n",
    "        \"bleu_score\": score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bleu_score = sum([x['bleu_score']['bleu_score'] for x in total_score]) / len(total_score)\n",
    "\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the output file path\n",
    "output_file = \"/home/mshahidul/project1/results/NLLB_direct.json\"\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(total_score, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Total score saved successfully to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EHR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "import pandas as pd\n",
    "from utils import compute_bleu_chrf,direct_translate\n",
    "import tqdm\n",
    "ehr_data = pd.read_excel('/home/mshahidul/project1/all_tran_data/EHR_data.xlsx')\n",
    "result_ehr=[]\n",
    "for x,y in tqdm.tqdm(zip(ehr_data['english'],ehr_data['spain'])):\n",
    "\n",
    "    trans=(direct_translate(x))\n",
    "    score=(compute_bleu_chrf(y,direct_translate(x)))\n",
    "    result_ehr.append({\n",
    "        \"original_english\": x,\n",
    "        \"original_spanish\": y,\n",
    "        \"translated_spanish\":trans,\n",
    "        \"bleu_score\": score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average BLEU score\n",
    "avg_bleu_score = sum([x['bleu_score']['bleu_score'] for x in result_ehr]) / len(result_ehr)\n",
    "\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the output file path\n",
    "output_file = \"/home/mshahidul/project1/all_tran_data/translated_EHR_data.json\"\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_ehr, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Translation saved successfully to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using COD prompt + reference text(Spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshahidul/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from openai import OpenAI  # Assuming OpenAI API is set up\n",
    "from utils import get_synonyms, back_translate, compute_bleu_chrf\n",
    "from openai import OpenAI \n",
    "client = OpenAI(api_key=\"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\")\n",
    "import json\n",
    "def translate_using_prompt(prompt,sentence):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate the following text from English into Spanish: {sentence}\"}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    ans=(response.choices[0].message.content)\n",
    "    return ans\n",
    "def back_translate(spa_tran):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": f\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate the following text from Spanish into English: {spa_tran}\"}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    return (response.choices[0].message.content)\n",
    "\n",
    "# Database connection details\n",
    "db_config = {\n",
    "    'host': '172.16.34.1',\n",
    "    'port': 3307,\n",
    "    'user': 'umls',\n",
    "    'password': 'umls',\n",
    "    'database': 'umls2024'\n",
    "}\n",
    "\n",
    "# Define the NLLB-200 model\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "cache_directory = \"/data/data_user_alpha/public_models\"\n",
    "\n",
    "# List of target languages\n",
    "languages = {\n",
    "    \"French\": \"fra_Latn\",\n",
    "    \"German\": \"deu_Latn\",\n",
    "    \"Portuguese\": \"por_Latn\",\n",
    "    \"Spanish\": 'spa_Latn'\n",
    "}\n",
    "\n",
    "# Load translation model\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_directory, torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_directory)\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain of dictionary: stress fracture means fractura por esfuerzo means Fractures de fatigue means Frakturen, Streß- means Fraturas de Estresse. bone means hueso means Maladies osseuses means Knochenkrankheiten means Doenças Ósseas. {'stress fracture': {'GER': 'Frakturen, Streß-', 'FRE': 'Fractures de fatigue', 'POR': 'Fraturas de Estresse', 'SPA': 'fractura por esfuerzo', 'ENG': 'stress fracture'}, 'bone': {'FRE': 'Maladies osseuses', 'GER': 'Knochenkrankheiten', 'POR': 'Doenças Ósseas', 'SPA': 'hueso', 'ENG': 'bone'}} ['stress fracture', 'hairline crack', 'bone', 'repeated forces', 'prolonged forces']\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def extract_keywords(sentence):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract medical keywords from the given sentence. return it as python list format without extra things.\"},\n",
    "                  {\"role\": \"user\", \"content\": f\"{sentence}\"}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    # keywords = json.loads(response.choices[0].message.content)\n",
    "    return (response.choices[0].message.content) \n",
    "\n",
    "def search_umls(keyword):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        cursor.execute(\"SELECT CUI FROM MRCONSO WHERE STR LIKE %s LIMIT 1\", (f\"%{keyword}%\",))\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            return None\n",
    "        cui = result[\"CUI\"]\n",
    "\n",
    "        cursor.execute(\"SELECT LAT, STR FROM MRCONSO WHERE CUI = %s AND LAT IN (%s, %s, %s)\",\n",
    "                       (cui, 'FRE', 'POR', 'GER'))\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        translations = {row['LAT']: row['STR'] for row in rows}\n",
    "        return translations\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error: {err}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "\n",
    "# def translate_non_medical(keyword):\n",
    "#     translations = {}\n",
    "#     for language, lang_code in languages.items():\n",
    "#         output = translator(keyword, src_lang=\"eng_Latn\", tgt_lang=lang_code, max_length=400)\n",
    "#         translations[language] = output[0]['translation_text']\n",
    "#     return translations\n",
    "\n",
    "def convert_to_chained_format(dictionary, src_lang, target_lang):\n",
    "    chain = []\n",
    "    \n",
    "    for category, words in dictionary.items():\n",
    "        for word, translations in words.items():\n",
    "            formatted_translations = []\n",
    "            \n",
    "            # Ensure the source language is first, target language second, then others\n",
    "            ordered_languages = [\"ENG\", \"SPA\", \"FRE\", \"GER\", \"POR\"]\n",
    "            \n",
    "            for lang in ordered_languages:\n",
    "                if lang in translations:\n",
    "                    formatted_translations.append(f\"{translations[lang]}\")\n",
    "\n",
    "            chain.append(\" means \".join(formatted_translations))\n",
    "    \n",
    "    chained_text = \". \".join(chain) + \".\"\n",
    "    return chained_text\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    keywords = extract_keywords(sentence)\n",
    "    import ast\n",
    "    keywords = ast.literal_eval(keywords)\n",
    "    medical_translations = {}\n",
    "    output=[]\n",
    "    # Process medical keywords\n",
    "    for keyword in keywords:\n",
    "        translation={}\n",
    "        translation = search_umls(keyword)\n",
    "        # print(keyword)\n",
    "        if translation and \"SPA\" not in translation:  # If Spanish missing in UMLS, use NLLB for Spanish\n",
    "            translation[\"SPA\"] = translator(keyword, src_lang=\"eng_Latn\", tgt_lang=\"spa_Latn\", max_length=400)[0]['translation_text']\n",
    "        \n",
    "        if translation:\n",
    "            translation['ENG'] = keyword\n",
    "            medical_translations[keyword] = translation\n",
    "\n",
    "    result_json_temp = {\n",
    "        \"medical\": medical_translations\n",
    "    }\n",
    "\n",
    "    src_language = \"English\"\n",
    "    target_language = \"Spanish\"\n",
    "\n",
    "    if medical_translations:\n",
    "        chained_output = convert_to_chained_format(result_json_temp, src_language, target_language)\n",
    "        full_prompt=\"Chain of dictionary: \"+chained_output\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "    return full_prompt, medical_translations, keywords\n",
    "\n",
    "# Example usage\n",
    "# sentence= sampled_medlineplus_data[50]['english']\n",
    "# print(sentence)\n",
    "sentence = \"A stress fracture is a hairline crack in the bone that develops because of repeated or prolonged forces against the bone.\"\n",
    "full_prompt,medical_translations,keywords = process_sentence(sentence)\n",
    "print(full_prompt,medical_translations,keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/mshahidul/project1/all_tran_data/Sampled_100_MedlinePlus_eng_spanish_pair.json\"\n",
    "output_data = []\n",
    "import tqdm\n",
    "import json\n",
    "from utils import translate_using_prompt\n",
    "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "    sampled_medlineplus_data = json.load(json_file)\n",
    "not_trans=[]\n",
    "for x in tqdm.tqdm(sampled_medlineplus_data):\n",
    "\n",
    "    sentence_eng=x['english']\n",
    "    sentence_spa=x['spanish']\n",
    "    try:\n",
    "        full_prompt,chain_of_dict,keywords = process_sentence(sentence_eng)\n",
    "        spa_tran=translate_using_prompt(full_prompt,sentence_eng)\n",
    "        reference_text = [sentence_spa]\n",
    "        hypothesis_text = spa_tran\n",
    "        scores_cod_prompt = compute_bleu_chrf(reference_text, hypothesis_text)\n",
    "    except:\n",
    "        not_trans.append(x)\n",
    "        continue\n",
    "\n",
    "    # full_prompt,chain_of_dict,keywords = process_sentence(sentence_eng)\n",
    "    \n",
    "    \n",
    "\n",
    "    output_data.append({\n",
    "        \"Original_English_sentence\": sentence_eng,\n",
    "        \"Original_Spanish_sentence\": sentence_spa,\n",
    "        \"spanish_translation\": spa_tran,\n",
    "        \"chain_of_dict\": chain_of_dict,\n",
    "        \"keywords\": keywords,\n",
    "        \"scores_cod_prompt(bleu and chrf)\": scores_cod_prompt,\n",
    "    })\n",
    "# save the output data to a JSON file\n",
    "output_file = \"/home/mshahidul/project1/all_tran_data/translated_MedlinePlus_100)_using_COD_prompt.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average BLEU and chrF++ scores\n",
    "total_bleu_score = sum([item['scores_cod_prompt(bleu and chrf)']['bleu_score'] for item in output_data])\n",
    "total_chrf_score = sum([item['scores_cod_prompt(bleu and chrf)']['chrF++'] for item in output_data])\n",
    "\n",
    "avg_bleu_score = total_bleu_score / len(output_data)\n",
    "avg_chrf_score = total_chrf_score / len(output_data)\n",
    "\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")\n",
    "print(f\"Average chrF++ Score: {avg_chrf_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
