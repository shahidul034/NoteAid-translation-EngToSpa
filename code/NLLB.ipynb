{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "from utils import direct_translate, back_translate, compute_bleu_chrf\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load EHR dataset\n",
    "# ehr_data = pd.read_excel('/home/mshahidul/project1/all_tran_data/dataset/EHR_data.xlsx')\n",
    "with open(\"/home/mshahidul/project1/all_tran_data/dataset/Sampled_100_MedlinePlus_eng_spanish_pair.json\", 'r', encoding='utf-8') as json_file:\n",
    "    sampled_medlineplus_data = json.load(json_file)\n",
    "# Define NLLB-200 model for translation\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "cache_directory = \"/data/data_user_alpha/public_models\"\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_directory, torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_directory)\n",
    "\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "def translate_nllb_english_to_spanish(text):\n",
    "    \"\"\"Translates English text to Spanish using NLLB-200.\"\"\"\n",
    "    output = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"spa_Latn\", max_length=400)\n",
    "    return output[0]['translation_text']\n",
    "\n",
    "output_data = []\n",
    "\n",
    "for x in tqdm.tqdm(sampled_medlineplus_data):\n",
    "    sentence_eng=x['english']\n",
    "    sentence_spa=x['spanish']\n",
    "    try:\n",
    "        # Translation using NLLB\n",
    "        spa_tran_nllb = translate_nllb_english_to_spanish(sentence_eng)\n",
    "        back_tran_nllb = back_translate(spa_tran_nllb) # ENglish convert\n",
    "\n",
    "        # Reference text for BLEU & CHRF calculations\n",
    "        reference_text = [sentence_eng]  # For back-translation evaluation\n",
    "        reference_text_spa = [sentence_spa]  # For direct translation evaluation\n",
    "\n",
    "        # Compute BLEU & CHRF scores\n",
    "        scores_nllb_back = compute_bleu_chrf(reference_text, back_tran_nllb)\n",
    "        # scores_direct_back = compute_bleu_chrf(reference_text, back_tran_direct)\n",
    "\n",
    "        scores_nllb_vs_spa = compute_bleu_chrf(reference_text_spa, spa_tran_nllb)\n",
    "        # scores_direct_vs_spa = compute_bleu_chrf(reference_text_spa, spa_tran_direct)\n",
    "\n",
    "        output_data.append({\n",
    "            \"Original_English_sentence\": sentence_eng,\n",
    "            \"Original_Spanish_sentence\": sentence_spa,\n",
    "            \"spanish_translation_nllb\": spa_tran_nllb,\n",
    "            \"back_translation_nllb\": back_tran_nllb,\n",
    "            \"scores_nllb(bleu and chrf) - Back Translation\": scores_nllb_back,\n",
    "            \"scores_nllb(bleu and chrf) - vs EHR Spanish\": scores_nllb_vs_spa\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}!!!!\")\n",
    "        continue\n",
    "\n",
    "# Save results\n",
    "json_path = \"/home/mshahidul/project1/results_new/ehr_nllb_direct_translation_vs_ehr.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data saved to {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bleu_score = sum([x['scores_nllb(bleu and chrf) - Back Translation']['bleu_score'] for x in output_data]) / len(output_data)\n",
    "\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
