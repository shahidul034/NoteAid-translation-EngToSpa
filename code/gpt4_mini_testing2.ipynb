{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using COD prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshahidul/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from openai import OpenAI  # Assuming OpenAI API is set up\n",
    "from utils import get_synonyms, back_translate, compute_bleu_chrf\n",
    "from openai import OpenAI \n",
    "client = OpenAI(api_key=\"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\")\n",
    "import json\n",
    "def translate_using_prompt(prompt,sentence):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate the following text from English into Spanish: {sentence}\"}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    ans=(response.choices[0].message.content)\n",
    "    return ans\n",
    "def back_translate(spa_tran):\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": f\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate the following text from Spanish into English: {spa_tran}\"}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    return (response.choices[0].message.content)\n",
    "\n",
    "# Database connection details\n",
    "db_config = {\n",
    "    'host': '172.16.34.1',\n",
    "    'port': 3307,\n",
    "    'user': 'umls',\n",
    "    'password': 'umls',\n",
    "    'database': 'umls2024'\n",
    "}\n",
    "\n",
    "# Define the NLLB-200 model\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "cache_directory = \"/data/data_user_alpha/public_models\"\n",
    "\n",
    "# List of target languages\n",
    "languages = {\n",
    "    \"French\": \"fra_Latn\",\n",
    "    \"German\": \"deu_Latn\",\n",
    "    \"Portuguese\": \"por_Latn\",\n",
    "    \"Spanish\": 'spa_Latn'\n",
    "}\n",
    "\n",
    "# Load translation model\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_directory, torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_directory)\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def extract_keywords(sentence):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract medical keywords from the given sentence. return it as python list format without extra things.\"},\n",
    "                  {\"role\": \"user\", \"content\": f\"{sentence}\"}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    # keywords = json.loads(response.choices[0].message.content)\n",
    "    return (response.choices[0].message.content) \n",
    "\n",
    "def search_umls(keyword):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        cursor.execute(\"SELECT CUI FROM MRCONSO WHERE STR LIKE %s LIMIT 1\", (f\"%{keyword}%\",))\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            return None\n",
    "        cui = result[\"CUI\"]\n",
    "\n",
    "        cursor.execute(\"SELECT LAT, STR FROM MRCONSO WHERE CUI = %s AND LAT IN (%s, %s, %s)\",\n",
    "                       (cui, 'FRE', 'POR', 'GER'))\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        translations = {row['LAT']: row['STR'] for row in rows}\n",
    "        return translations\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error: {err}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "\n",
    "# def translate_non_medical(keyword):\n",
    "#     translations = {}\n",
    "#     for language, lang_code in languages.items():\n",
    "#         output = translator(keyword, src_lang=\"eng_Latn\", tgt_lang=lang_code, max_length=400)\n",
    "#         translations[language] = output[0]['translation_text']\n",
    "#     return translations\n",
    "\n",
    "def convert_to_chained_format(dictionary, src_lang, target_lang):\n",
    "    chain = []\n",
    "    \n",
    "    for category, words in dictionary.items():\n",
    "        for word, translations in words.items():\n",
    "            formatted_translations = []\n",
    "            \n",
    "            # Ensure the source language is first, target language second, then others\n",
    "            ordered_languages = [\"ENG\", \"SPA\", \"FRE\", \"GER\", \"POR\"]\n",
    "            \n",
    "            for lang in ordered_languages:\n",
    "                if lang in translations:\n",
    "                    formatted_translations.append(f\"{translations[lang]}\")\n",
    "\n",
    "            chain.append(\" means \".join(formatted_translations))\n",
    "    \n",
    "    chained_text = \". \".join(chain) + \".\"\n",
    "    return chained_text\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    keywords = extract_keywords(sentence)\n",
    "    import ast\n",
    "    keywords = ast.literal_eval(keywords)\n",
    "    medical_translations = {}\n",
    "    output=[]\n",
    "    # Process medical keywords\n",
    "    for keyword in keywords:\n",
    "        translation={}\n",
    "        translation = search_umls(keyword)\n",
    "        # print(keyword)\n",
    "        if translation and \"SPA\" not in translation:  # If Spanish missing in UMLS, use NLLB for Spanish\n",
    "            translation[\"SPA\"] = translator(keyword, src_lang=\"eng_Latn\", tgt_lang=\"spa_Latn\", max_length=400)[0]['translation_text']\n",
    "        \n",
    "        if translation:\n",
    "            translation['ENG'] = keyword\n",
    "            medical_translations[keyword] = translation\n",
    "\n",
    "    result_json_temp = {\n",
    "        \"medical\": medical_translations\n",
    "    }\n",
    "\n",
    "    src_language = \"English\"\n",
    "    target_language = \"Spanish\"\n",
    "\n",
    "    if medical_translations:\n",
    "        chained_output = convert_to_chained_format(result_json_temp, src_language, target_language)\n",
    "        full_prompt=\"Chain of dictionary: \"+chained_output\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "    return full_prompt, medical_translations, keywords\n",
    "\n",
    "# Example usage\n",
    "# sentence= sampled_medlineplus_data[50]['english']\n",
    "# print(sentence)\n",
    "# sentence = \"A stress fracture is a hairline crack in the bone that develops because of repeated or prolonged forces against the bone.\"\n",
    "# full_prompt,medical_translations,keywords = process_sentence(sentence)\n",
    "# print(full_prompt,medical_translations,keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "from utils import translate_using_prompt,direct_translate\n",
    "output_data=[]\n",
    "file_path = \"/home/mshahidul/project1/all_tran_data/dataset/Sampled_100_MedlinePlus_eng_spanish_pair.json\"\n",
    "import tqdm\n",
    "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "    sampled_medlineplus_data = json.load(json_file)\n",
    "not_trans=[]\n",
    "for x in tqdm.tqdm(sampled_medlineplus_data):\n",
    "\n",
    "    sentence_eng=x['english']\n",
    "    sentence_spa=x['spanish']\n",
    "    try:\n",
    "        full_prompt,medical_translations,keywords = process_sentence(sentence_eng)\n",
    "        spa_tran_prompt=translate_using_prompt(full_prompt,sentence_eng)\n",
    "        spa_tran_direct=direct_translate(sentence_eng)\n",
    "        back_tran_prompt=back_translate(spa_tran_prompt)\n",
    "        back_tran_direct=back_translate(spa_tran_direct)\n",
    "        reference_text = [sentence_eng]\n",
    "        hypothesis_text = back_tran_prompt\n",
    "        scores_cod_prompt = compute_bleu_chrf(reference_text, hypothesis_text)\n",
    "        hypothesis_text = back_tran_direct\n",
    "        scores_direct = compute_bleu_chrf(reference_text, hypothesis_text)\n",
    "        output_data.append({\n",
    "            \"Original_English_sentence\": sentence_eng,\n",
    "            \"Original_Spanish_sentence\": sentence_spa,\n",
    "            \"COD_prompt\": full_prompt,\n",
    "            \"spanish_translation_prompt\": spa_tran_prompt,\n",
    "            \"spanish_translation_direct\": spa_tran_direct,\n",
    "             \"back_translation_prompt\": back_tran_prompt,\n",
    "            \"back_translation_direct\": back_tran_direct,\n",
    "            \"scores_cod_prompt(bleu and chrf)\": scores_cod_prompt,\n",
    "            \"scores_direct(bleu and chrf)\": scores_direct\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}!!!!\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "json_path = \"/home/mshahidul/project1/results_new/medlineplus_gpt4_mini_COD_back_translation.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [03:36,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /home/mshahidul/project1/results_new/ehr_gpt4_mini_COD_back_translation_direct.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "from utils import translate_using_prompt,direct_translate\n",
    "output_data=[]\n",
    "file_path = \"/home/mshahidul/project1/all_tran_data/dataset/Sampled_100_MedlinePlus_eng_spanish_pair.json\"\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "ehr_data = pd.read_excel('/home/mshahidul/project1/all_tran_data/dataset/EHR_data.xlsx')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "# print(ehr_data.head())\n",
    "\n",
    "for eng,spa in tqdm.tqdm(zip(ehr_data[\"english\"],ehr_data[\"spain\"])):\n",
    "    sentence_eng=eng\n",
    "    sentence_spa=spa\n",
    "    try:\n",
    "        # full_prompt,medical_translations,keywords = process_sentence(sentence_eng)\n",
    "        # spa_tran_prompt=translate_using_prompt(full_prompt,sentence_eng)\n",
    "        spa_tran_direct=direct_translate(sentence_eng)\n",
    "        # back_tran_prompt=back_translate(spa_tran_prompt)\n",
    "        back_tran_direct=back_translate(spa_tran_direct)\n",
    "        reference_text = [sentence_eng]\n",
    "        # hypothesis_text = back_tran_prompt\n",
    "        # scores_cod_prompt = compute_bleu_chrf(reference_text, hypothesis_text)\n",
    "        hypothesis_text = back_tran_direct\n",
    "        scores_direct = compute_bleu_chrf(reference_text, hypothesis_text)\n",
    "        output_data.append({\n",
    "            \"Original_English_sentence\": sentence_eng,\n",
    "            \"Original_Spanish_sentence\": sentence_spa,\n",
    "            # \"COD_prompt\": full_prompt,\n",
    "            # \"spanish_translation_prompt\": spa_tran_prompt,\n",
    "            \"spanish_translation_direct\": spa_tran_direct,\n",
    "            #  \"back_translation_prompt\": back_tran_prompt,\n",
    "            \"back_translation_direct\": back_tran_direct,\n",
    "            # \"scores_cod_prompt(bleu and chrf)\": scores_cod_prompt,\n",
    "            \"scores_direct(bleu and chrf)\": scores_direct\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}!!!!\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "json_path = \"/home/mshahidul/project1/results_new/ehr_gpt4_mini_COD_back_translation_direct.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original_English_sentence': '[Report de-identified (Safe-harbor compliant) by De-ID v.6.22.08.0] **INSTITUTION GENERAL MEDICINE ATTENDING PHYSICIAN PROGRESS NOTE PATIENT NAME: **NAME[AAA, BBB M] ACCOUNT #: **ID-NUM **ROOM ATTENDING PHYSICIAN: **NAME[BBB M ZZZ] ADMISSION DATE: **DATE[Apr 11 2007] EVALUATION DATE: **DATE[Apr 18 07] The patient is awake and alert.', 'Original_Spanish_sentence': '[Informe de-identificado (cumple con Puerto Seguro) por De-ID v.6.22.08.0] **INSTITUCION MEDICINA GENERAL MEDICO PRIMARIO NOTA DE PROGRESO NOMBRE DEL PACIENTE: **NOMBRE[AAA, BBB M] # CUENTA: **NUM-ID- **CUARTO MEDICO PRIMARIO: **NOMBRE[BBB M ZZZ] FECHA DE ADMISION: **FECHA[11 abr 2007] FECHA DE EVALUACION: **FECHA[18 abr 07] El pacient está despierto y alerta.', 'spanish_translation_direct': '[Informe desidentificado (cumple con Safe-harbor) por De-ID v.6.22.08.0] **INSTITUCIÓN NOTA DE PROGRESO DEL MÉDICO DE MEDICINA GENERAL NOMBRE DEL PACIENTE: **NOMBRE[AAA, BBB M] NÚMERO DE CUENTA: **ID-NUM **SALÓN MÉDICO ASISTENTE: **NOMBRE[BBB M ZZZ] FECHA DE ADMISIÓN: **FECHA[11 de abr 2007] FECHA DE EVALUACIÓN: **FECHA[18 de abr 07] El paciente está despierto y alerta.', 'back_translation_direct': '[De-identified report (complies with Safe Harbor) by De-ID v.6.22.08.0] **INSTITUTION PROGRESS NOTE FROM GENERAL MEDICINE PHYSICIAN PATIENT NAME: **NAME[AAA, BBB M] ACCOUNT NUMBER: **ID-NUM **ASSISTING MEDICAL ROOM: **NAME[BBB M ZZZ] ADMISSION DATE: **DATE[April 11, 2007] EVALUATION DATE: **DATE[April 18, 2007] The patient is awake and alert.', 'scores_direct(bleu and chrf)': {'bleu_score': 64.39717467584798, 'chrF++': 0.4291845493562232}}\n",
      "\n",
      "Average Scores for Direct Translation:\n",
      "  BLEU: 56.76\n",
      "  chrF++: 2.37\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_path = \"/home/mshahidul/project1/results_new/ehr_gpt4_mini_COD_back_translation.json\"\n",
    "with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "    output_data = json.load(json_file)\n",
    "print(output_data[0])\n",
    "# Function to calculate average scores\n",
    "def calculate_average_scores(output_data):\n",
    "    # Initialize sums\n",
    "    total_bleu_prompt = 0\n",
    "    total_chrf_prompt = 0\n",
    "    total_bleu_direct = 0\n",
    "    total_chrf_direct = 0\n",
    "    num_entries = len(output_data)\n",
    "\n",
    "    if num_entries == 0:\n",
    "        return {\n",
    "            \"avg_bleu_prompt\": 0,\n",
    "            \"avg_chrf_prompt\": 0,\n",
    "            \"avg_bleu_direct\": 0,\n",
    "            \"avg_chrf_direct\": 0\n",
    "        }\n",
    "\n",
    "    # Sum scores from each entry\n",
    "    for entry in output_data:\n",
    "        scores_prompt = entry[\"scores_cod_prompt(bleu and chrf)\"]\n",
    "        # scores_direct = entry[\"scores_direct(bleu and chrf)\"]\n",
    "        \n",
    "        total_bleu_prompt += scores_prompt[\"bleu_score\"]\n",
    "        total_chrf_prompt += scores_prompt[\"chrF++\"]\n",
    "        # total_bleu_direct += scores_direct[\"bleu_score\"]\n",
    "        # total_chrf_direct += scores_direct[\"chrF++\"]\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_bleu_prompt = total_bleu_prompt / num_entries\n",
    "    avg_chrf_prompt = total_chrf_prompt / num_entries\n",
    "    # avg_bleu_direct = total_bleu_direct / num_entries\n",
    "    # avg_chrf_direct = total_chrf_direct / num_entries\n",
    "\n",
    "    return {\n",
    "        \"avg_bleu_prompt\": avg_bleu_prompt,\n",
    "        \"avg_chrf_prompt\": avg_chrf_prompt,\n",
    "        # \"avg_bleu_direct\": avg_bleu_direct,\n",
    "        # \"avg_chrf_direct\": avg_chrf_direct\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Calculate average scores\n",
    "avg_scores = calculate_average_scores(output_data)\n",
    "\n",
    "# Print results\n",
    "# print(\"Average Scores for Prompt-based Translation:\")\n",
    "# print(f\"  BLEU: {avg_scores['avg_bleu_prompt']:.2f}\")\n",
    "# print(f\"  chrF++: {avg_scores['avg_chrf_prompt']:.2f}\")\n",
    "print(\"\\nAverage Scores for Direct Translation:\")\n",
    "print(f\"  BLEU: {avg_scores['avg_bleu_direct']:.2f}\")\n",
    "print(f\"  chrF++: {avg_scores['avg_chrf_direct']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
