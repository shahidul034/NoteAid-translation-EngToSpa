
## Phi-4 (Finetune) (gpt)

| Contextual Information | Direct Avg BLEU | Direct Avg chrF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| Synonyms of each concept derived from GPT-4o Mini | 42.10 | 29.47 | 0.86270 | 100 |
| ✅ Multilingual translations of each concept obtained from GPT-4o Mini | 44.23 | 28.91 | 0.86299 | 100 |
| Translation dictionary based on UMLS | 41.38 | 25.39 | 0.85409 | 100 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 42.52 | 28.35 | 0.86159 | 100 |

---

## Phi-4 (Without Finetune) (Alpaca)

| Contextual Information | Direct Avg BLEU | Direct Avg chrF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| Synonyms of each concept derived from GPT-4o Mini | 32.71 | 21.86 | 0.819 | 95 |
| Multilingual translations of each concept obtained from GPT-4o Mini | 24.47 | 12.89 | 0.790 | 97 |
| Translation dictionary based on UMLS | 35.89 | 20.17 | 0.835 | 91 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 18.77 | 8.79 | 0.643 | 65 |

---

## Qwen2.5 14B (Finetune) (GPT)

| Contextual Information | Direct Avg BLEU | Direct Avg chrF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| ✅ Multilingual translations of each concept obtained from GPT-4o Mini | 41.95 | 25.93 | 0.8614 | 100 |
| Synonyms of each concept derived from GPT-4o Mini | 39.17 | 23.82 | 0.8572 | 100 |
| Translation dictionary based on UMLS | 39.47 | 26.28 | 0.8511 | 100 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 38.63 | 23.53 | 0.8491 | 100 |

---

## Qwen2.5 14B (Without Finetune) (Alpaca)

| Contextual Information | Direct Avg BLEU | Direct Avg CHRF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| Translation dictionary based on UMLS | 34.18 | 21.77 | 0.8399 | 100 |
| Synonyms of each concept derived from GPT-4o Mini | 33.05 | 21.60 | 0.8420 | 100 |
| ✅ Multilingual translations of each concept obtained from GPT-4o Mini | 41.95 | 25.93 | 0.8614 | 100 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 31.23 | 18.012 | 0.83 | 100 |

---

## Meta-Llama-3.1-8B-Instruct (Finetune) (Alpaca)

| Contextual Information | Direct Avg BLEU | Direct Avg CHRF+ | Direct Avg COMET |
|------------------------|----------------|------------------|------------------|
| ✅ Synonyms of each concept derived from GPT-4o Mini | 34.47 | 23.25 | 0.8526 |
| Translation dictionary based on UMLS | 34.47 | 21.10 | 0.8483 |
| Multilingual translations of each concept from GPT-4o Mini | 33.15 | 19.67 | 0.8481 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 33.12 | 22.11 | 0.8502 |

---

## Meta-Llama-3.1-8B-Instruct (Without Finetune) (Alpaca)

| Contextual Information | Direct Avg BLEU | Direct Avg CHRF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| ✅ Synonyms of each concept derived from GPT-4o Mini | 30.224 | 20.07 | 0.798 | 100 |
| Translation dictionary based on UMLS | 27.54 | 19.23 | 0.7921 | 100 |
| Multilingual translations of each concept obtained from GPT-4o Mini | 28.637 | 21.84 | 0.8083 | 100 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 27.65 | 14.98 | 0.797 | 100 |

---

## Qwen2.5 7B (Finetune) (GPT)

| Contextual Information | Direct Avg BLEU | Direct Avg chrF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| Translation dictionary based on UMLS | 39.09 | 24.10 | 0.8565 | 98 |
| Synonyms of each concept derived from GPT-4o Mini | 38.43 | 24.05 | 0.8580 | 97 |
| ✅ Multilingual translations of each concept obtained from GPT-4o Mini | 38.86 | 22.80 | 0.8565 | 100 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 38.86 | 23.94 | 0.8555 | 96 |

---

## Qwen2.5 7B (Without Finetune) (GPT)

| Contextual Information | Direct Avg BLEU | Direct Avg chrF+ | Direct Avg COMET | Total Data |
|------------------------|----------------|------------------|------------------|------------|
| ✅ Multilingual translations of each concept obtained from GPT-4o Mini | 33.40 | 20.35 | 0.8451 | 100 |
| Synonyms of each concept derived from GPT-4o Mini | 31.07 | 19.14 | 0.8211 | 99 |
| Translation dictionary based on UMLS | 24.50 | 16.58 | 0.7607 | 99 |
| ![#1589F0](https://placehold.co/15x15/1589F0/1589F0.png) Direct translation without context | 26.91 | 20.29 | 0.80 | 100 |

---

## gemma-3-4b-it (Finetune)

| Contextual Information | Direct Avg BLEU | Direct Avg CHRF+ | Direct Avg COMET | Total Number of Data |
|------------------------|----------------|------------------|------------------|----------------------|
| Multilingual translations from GPT-4o Mini | 33.54 | 20.65 | 0.8504 | 92 |
| Translation dictionary based on UMLS | 31.94 | 21.00 | 0.8031 | 100 |
| Direct translation without context | 31.08 | 20.36 | 0.8084 | 100 |
| Synonyms of each concept from GPT-4o Mini | 35.33 | 20.55 | 0.8507 | 98 |

---

## gemma-3-4b-it (Without Finetune)

| Contextual Information | Direct Avg BLEU | Direct Avg CHRF+ | Direct Avg COMET | Total Number of Data |
|------------------------|----------------|------------------|------------------|----------------------|
| Synonyms of each concept derived from GPT-4o Mini | 32.28 | 20.90 | 0.8077 | 100 |
| Translation dictionary based on UMLS | 31.84 | 21.30 | 0.8031 | 100 |
| Direct translation without context | 31.17 | 20.35 | 0.8085 | 100 |
| Multilingual translations from GPT-4o Mini | 31.72 | 21.46 | 0.8016 | 100 |

---

